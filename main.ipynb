{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 16:57:51.282905: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-10 16:57:51.402883: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-10 16:57:51.403043: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-10 16:57:51.407504: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-10 16:57:51.427534: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-10 16:57:51.431078: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-10 16:57:55.245527: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pretty_errors\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "from matplotlib.pylab import f\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cvnn.layers as complex_layers\n",
    "import matplotlib.pyplot as plt\n",
    "from cvnn.activations import modrelu, zrelu, crelu, cart_softmax\n",
    "from cvnn.losses import ComplexAverageCrossEntropy\n",
    "\n",
    "\n",
    "def get_model() -> tf.keras.Model:\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    layers = [\n",
    "        complex_layers.ComplexInput(input_shape=(28, 28, 1)),  # Input layer for 2D images\n",
    "        complex_layers.ComplexFlatten(),  # Flatten the 2D images to 1D\n",
    "        complex_layers.ComplexDense(10, activation=modrelu, use_bias=True),\n",
    "        complex_layers.ComplexDense(120, activation=modrelu, use_bias=True),\n",
    "        complex_layers.ComplexDense(10, activation=cart_softmax, use_bias=True)\n",
    "        ]\n",
    "    \n",
    "    for layer in layers:\n",
    "        model.add(layer)\n",
    "    return model\n",
    "\n",
    "def load_complex_dataset(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"Loads the MNIST dataset and applies the 2D Discrete Fourier Transform (DFT) to each image.\n",
    "    Args:\n",
    "        x_train (numpy.ndarray): The training images, shape (num_samples, 28, 28).\n",
    "        y_train (numpy.ndarray): The labels for the training images.\n",
    "        x_test (numpy.ndarray): The test images, shape (num_samples, 28, 28).\n",
    "        y_test (numpy.ndarray): The labels for the test images.\n",
    "    returns: A tuple containing the transformed training and test datasets.\n",
    "    \"\"\"\n",
    "    \n",
    "    x_train_complex = []\n",
    "    x_test_complex = []\n",
    "    for train_sample in x_train:\n",
    "        # Apply the 2D Discrete Fourier Transform\n",
    "        train_complex_image = np.fft.fft2(train_sample)\n",
    "\n",
    "        # The output of the DFT is often shifted to have the zero-frequency component (DC component) in the center for visualization purposes.\n",
    "        train_shifted_complex_image = np.fft.fftshift(train_complex_image)\n",
    "        x_train_complex.append(train_shifted_complex_image)\n",
    "    for test_sample in x_test:\n",
    "        # Apply the 2D Discrete Fourier Transform\n",
    "        test_complex_image = np.fft.fft2(test_sample)\n",
    "\n",
    "        # The output of the DFT is often shifted to have the zero-frequency component (DC component) in the center for visualization purposes.\n",
    "        test_shifted_complex_image = np.fft.fftshift(test_complex_image)\n",
    "        x_test_complex.append(test_shifted_complex_image)\n",
    "    return (np.array(x_train_complex), y_train), (np.array(x_test_complex), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train data shape: (60000, 28, 28), Train labels shape: (60000, 10)\n",
      "Test data shape: (10000, 28, 28), Test labels shape: (10000, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(real_images_train, labels_train), (real_images_test, labels_test) = tf.keras.datasets.mnist.load_data() # real data\n",
    "(complex_images_train, _), (complex_images_test, _) = load_complex_dataset(real_images_train, labels_train, real_images_test, labels_test) # complex data (2d DFT)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "labels_train = tf.keras.utils.to_categorical(labels_train, 10)\n",
    "labels_test = tf.keras.utils.to_categorical(labels_test, 10)\n",
    "\n",
    "# flatten images \n",
    "print(f'\\nTrain data shape: {complex_images_train.shape}, Train labels shape: {labels_train.shape}')\n",
    "print(f'Test data shape: {complex_images_test.shape}, Test labels shape: {labels_test.shape}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " complex_flatten (ComplexFl  (None, 784)               0         \n",
      " atten)                                                          \n",
      "                                                                 \n",
      " complex_dense (ComplexDens  (None, 10)                15700     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " complex_dense_1 (ComplexDe  (None, 120)               2640      \n",
      " nse)                                                            \n",
      "                                                                 \n",
      " complex_dense_2 (ComplexDe  (None, 10)                2420      \n",
      " nse)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20760 (81.09 KB)\n",
      "Trainable params: 20760 (81.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------ sample code ------------\n",
    "epochs = 100\n",
    "\n",
    "# Assume you already have complex data... example numpy arrays of dtype np.complex64\n",
    "model = get_model()   # Get your model\n",
    "\n",
    "# Compile as any TensorFlow model\n",
    "model.compile(optimizer='adam', metrics=['accuracy'],\n",
    "            loss=ComplexAverageCrossEntropy())\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train and evaluate\n",
    "history = model.fit(complex_images_train, labels_train, epochs=epochs, validation_data=(complex_images_test, labels_test))\n",
    "test_loss, test_acc = model.evaluate(complex_images_test,  labels_test, verbose=2)\n",
    "print(f'\\nTest accuracy: {test_acc:.4f}')\n",
    "print(f'Test loss: {test_loss:.4f}')\n",
    "print(f'History: {history.history}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvnn_3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
